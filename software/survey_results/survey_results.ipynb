{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5cd2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0e8abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data = pd.read_csv('../survey/survey_data.csv')\n",
    "\n",
    "n = 5\n",
    "\n",
    "survey_responses = pd.read_csv('FINAL_SMALL.csv')\n",
    "survey_responses_2 = pd.read_csv('FINAL_SMALL_2.csv')\n",
    "survey_responses_3 = pd.read_csv('FINAL_SMALL_3.csv')\n",
    "survey_responses_4 = pd.read_csv('FINAL_SMALL_4.csv')\n",
    "survey_responses_5 = pd.read_csv('FINAL_SMALL_5.csv')\n",
    "survey_responses_6 = pd.read_csv('FINAL_SMALL_6.csv')\n",
    "\n",
    "all_responses = [survey_responses, survey_responses_2, survey_responses_3, survey_responses_4, survey_responses_5, survey_responses_6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64bf392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = survey_data.iloc[0][['Method_1', 'Method_2', 'Method_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78845e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43c2e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(df, success_only=False):\n",
    "    questions = [x for x in df.columns if '_mc_' in x]\n",
    "    qids = set([x.split('_')[2] for x in questions])\n",
    "    \n",
    "    rows = {qid: {k: [] for k in method_names} for qid in qids}\n",
    "    for question in questions:\n",
    "        split = question.split('_')\n",
    "        qid = split[2]\n",
    "        method = split[3]\n",
    "        \n",
    "        if success_only:\n",
    "            if not survey_data[survey_data['Question_ID'] == int(qid)].iloc[0][f'{method}_Success']:\n",
    "                continue\n",
    "\n",
    "        ratings = df[question].dropna().iloc[2:].to_list()\n",
    "        for rating in ratings:\n",
    "            rows[qid][method].append(int(rating))\n",
    "            \n",
    "        rows[qid][method] = rows[qid][method][:5]\n",
    "            \n",
    "    all_ratings = {k: [] for k in method_names}\n",
    "\n",
    "    for row in rows:\n",
    "        for method in rows[row]:\n",
    "            if len(rows[row][method]) > 0:\n",
    "                all_ratings[method].append(np.mean(rows[row][method]))\n",
    "    \n",
    "    return all_ratings, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22b743b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings, rows = get_results(survey_responses)\n",
    "\n",
    "all_ratings_2, rows_2 = get_results(survey_responses_2)\n",
    "\n",
    "all_ratings_3, rows_3 = get_results(survey_responses_3)\n",
    "\n",
    "all_ratings_4, rows_4 = get_results(survey_responses_4)\n",
    "\n",
    "all_ratings_5, rows_5 = get_results(survey_responses_5)\n",
    "\n",
    "all_ratings_6, rows_6 = get_results(survey_responses_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbc50dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_all_ratings = [all_ratings, all_ratings_2, all_ratings_3, all_ratings_4, all_ratings_5, all_ratings_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27aaf215",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_only = False\n",
    "all_rows = {}\n",
    "for responses in all_responses:\n",
    "    all_ratings, rows = get_results(responses, success_only)\n",
    "    all_rows |= rows\n",
    "\n",
    "averaged = {name: [] for name in method_names}\n",
    "means = {str(i): {name: {} for name in method_names} for i in range(n)}\n",
    "for i in range(n):\n",
    "    i = str(i)\n",
    "    for method in method_names:\n",
    "        if len(all_rows[i][method]) == 0:\n",
    "            continue\n",
    "        \n",
    "        means[i][method] = {}\n",
    "        \n",
    "        means[i][method]['mean'] = np.mean(all_rows[i][method])\n",
    "        means[i][method]['std'] = np.std(all_rows[i][method])\n",
    "        \n",
    "        averaged[method].append(means[i][method]['mean'])\n",
    "        \n",
    "all_averages = {}\n",
    "        \n",
    "for method in method_names:\n",
    "    average = np.mean(averaged[method])\n",
    "    std = np.std(averaged[method])\n",
    "    \n",
    "    all_averages[method] = averaged[method]\n",
    "    \n",
    "    averaged[method] = {'average': average, 'std': std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb92117",
   "metadata": {},
   "source": [
    "**ALL**\n",
    "\n",
    "| Generator |   Fluency       |\n",
    "|-----------|-----------------|\n",
    "| PPLM | 2.86 (0.67)     |\n",
    "| Polyjuice      | 3.40 (0.94)     |\n",
    "| RELITC    | **3.43** (0.79) |\n",
    "\n",
    "**SUCCESSFUL CE ONLY**\n",
    "\n",
    "| Generator |   Fluency       |\n",
    "|-----------|-----------------|\n",
    "| PPLM | 2.96 (0.65)     | \n",
    "| Polyjuice      | 3.19 (1.03)     | \n",
    "| RELITC    | **3.35** (0.83) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff090a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = [np.array([np.mean(ratings[x]) for x in ratings]) for ratings in all_all_ratings]\n",
    "all_stds = [np.array([np.std(ratings[x]) for x in ratings]) for ratings in all_all_ratings]\n",
    "\n",
    "# means_1 = np.array([np.mean(all_ratings[x]) for x in all_ratings])\n",
    "# stds_1 = np.array([np.std(all_ratings[x]) for x in all_ratings])\n",
    "\n",
    "# means_2 = np.array([np.mean(all_ratings_2[x]) for x in all_ratings_2])\n",
    "# stds_2 = np.array([np.std(all_ratings_2[x]) for x in all_ratings_2])\n",
    "\n",
    "# means_3 = np.array([np.mean(all_ratings_3[x]) for x in all_ratings_3])\n",
    "# stds_3 = np.array([np.std(all_ratings_3[x]) for x in all_ratings_3])\n",
    "\n",
    "# means_4 = np.array([np.mean(all_ratings_4[x]) for x in all_ratings_4])\n",
    "# stds_4 = np.array([np.std(all_ratings_4[x]) for x in all_ratings_4])\n",
    "\n",
    "means = np.mean(all_means, axis=0)\n",
    "stds = np.mean(all_stds, axis=0)\n",
    "\n",
    "xs = np.arange(len(method_names))\n",
    "\n",
    "plt.grid(axis='y', linestyle=\"--\", alpha=0.5, zorder=1)\n",
    "\n",
    "offset = 1 / (len(all_means) + 2)\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(all_means, all_stds)):\n",
    "    plt.bar(xs+(offset*i), mean, yerr=(std), width=offset, label=f'Batch {i+1}', capsize=5)\n",
    "\n",
    "# plt.bar(xs, means_1, yerr=(stds_1), width=offset, label='1st Batch', capsize=5)\n",
    "# plt.bar(xs+offset, means_2, yerr=(stds_2), width=offset, label='2nd Batch', capsize=5)\n",
    "# plt.bar(xs+2*offset, means_3, yerr=(stds_3), width=offset, label='3rd Batch', capsize=5)\n",
    "# plt.bar(xs+3*offset, means_4, yerr=(stds_4), width=offset, label='4th Batch', capsize=5)\n",
    "plt.bar(xs+offset*(len(means)+3), means, yerr=(stds), width=offset, label='Mean', capsize=5)\n",
    "\n",
    "plt.xticks(xs + offset * (len(means) / 2 + 1), method_names)\n",
    "plt.title('Four batches of ratings')\n",
    "plt.legend()\n",
    "plt.savefig('fourth_batch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_means, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da143354",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in all_ratings:\n",
    "    print(method, np.mean(all_ratings[method]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "936d3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses = [survey_responses, survey_responses_2, survey_responses_3, survey_responses_4, survey_responses_5, survey_responses_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38fa33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions = [[x for x in responses.columns if '_mc_' in x] for responses in all_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b3d96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_1 = [x for x in survey_responses.columns if '_mc_' in x]\n",
    "questions_2 = [x for x in survey_responses_2.columns if '_mc_' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3e53647",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings_per_person = [[row.dropna().astype(int).to_list() for i, row in responses.iloc[2:][questions].iterrows() if len(row.dropna()) > 0] for responses, questions in zip(all_responses, all_questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d33047f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_person_1 = [row.dropna().astype(int).to_list() for i, row in survey_responses.iloc[2:][questions_1].iterrows() if len(row.dropna()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "494edc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_person_2 = [row.dropna().astype(int).to_list() for i, row in survey_responses_2.iloc[2:][questions_2].iterrows() if len(row.dropna()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4728d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_pp = [[np.mean(x) for x in ratings_per_person] for ratings_per_person in all_ratings_per_person]\n",
    "stds_pp = [[np.std(x) for x in ratings_per_person] for ratings_per_person in all_ratings_per_person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86aba519",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_pp_1 = [np.mean(x) for x in ratings_per_person_1]\n",
    "means_pp_2 = [np.mean(x) for x in ratings_per_person_2]\n",
    "stds_pp_1 = [np.std(x) for x in ratings_per_person_1]\n",
    "stds_pp_2 = [np.std(x) for x in ratings_per_person_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefaf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid(axis='y', linestyle=\"--\", alpha=0.5, zorder=1)\n",
    "\n",
    "for i in range(len(means_pp)):\n",
    "    num_responses = len(means_pp[i])\n",
    "    plt.scatter([i+1]*num_responses, means_pp[i])\n",
    "    if i == 0:\n",
    "        plt.scatter([i+1]*num_responses, stds_pp[i], color='black', label='SD')\n",
    "        plt.scatter([i+1], np.mean(means_pp[i]), color='blue', label='Mean')\n",
    "        plt.scatter([i+1], np.mean(stds_pp[i]), color='red', label='Mean SD')\n",
    "    else:\n",
    "        plt.scatter([i+1]*num_responses, stds_pp[i], color='black')\n",
    "        plt.scatter([i+1], np.mean(means_pp[i]), color='blue')\n",
    "        plt.scatter([i+1], np.mean(stds_pp[i]), color='red')\n",
    "        \n",
    "\n",
    "# plt.scatter([1]*5, means_pp_1)\n",
    "# plt.scatter([2]*5, means_pp_2)\n",
    "# plt.scatter([1]*5, stds_pp_1, label='Std', color='black')\n",
    "# plt.scatter([2]*5, stds_pp_2, color='black')\n",
    "\n",
    "ticks = [f'Batch {i}' for i in range(1, len(means_pp) + 1)]\n",
    "xs = np.arange(len(ticks))\n",
    "plt.xticks(xs+1, ticks)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(-0.2, 5.2)\n",
    "plt.xlim(0, 7)\n",
    "plt.title('Ratings per respondent (mean, std)')\n",
    "plt.savefig('respondents_ratings.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bp1 = ax.violinplot(means_pp, widths=0.5, showmeans=True)\n",
    "bp2 = ax.violinplot(stds_pp, widths=0.5, showmeans=True)\n",
    "\n",
    "for pc in bp1['bodies']:\n",
    "    pc.set_facecolor('aliceblue')\n",
    "    pc.set_edgecolor('tab:blue')\n",
    "    pc.set_alpha(1)\n",
    "    \n",
    "for partname in ('cbars','cmins','cmaxes','cmeans'):\n",
    "    vp = bp1[partname]\n",
    "    vp.set_edgecolor('tab:blue')\n",
    "    vp.set_linewidth(1)\n",
    "    \n",
    "for pc in bp2['bodies']:\n",
    "    pc.set_facecolor('lightgrey')\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(1)\n",
    "    \n",
    "for partname in ('cbars','cmins','cmaxes','cmeans'):\n",
    "    vp = bp2[partname]\n",
    "    vp.set_edgecolor('black')\n",
    "    vp.set_linewidth(1)\n",
    "\n",
    "\n",
    "ax.legend([bp1[\"bodies\"][0], bp2[\"bodies\"][0]], ['Ratings', 'SD'], loc='upper right')\n",
    "\n",
    "ticks = [f'Batch {i}' for i in range(1, len(means_pp) + 1)]\n",
    "xs = np.arange(len(ticks))\n",
    "plt.xticks(xs + 1, ticks)\n",
    "\n",
    "plt.grid(axis='y', linestyle=\"--\", alpha=0.5, zorder=1)\n",
    "\n",
    "plt.ylim(-0.2, 5.2)\n",
    "plt.xlim(0.5, 6.5)\n",
    "\n",
    "plt.title('Ratings per respondent')\n",
    "\n",
    "plt.savefig('respondents_ratings_violin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bp1 = ax.boxplot(means_pp, widths=0.35, patch_artist=True, boxprops=dict(facecolor=\"C0\"))\n",
    "bp2 = ax.boxplot(stds_pp, widths=0.35, patch_artist=True, boxprops=dict(facecolor=\"C2\"))\n",
    "\n",
    "ax.legend([bp1[\"boxes\"][0], bp2[\"boxes\"][0]], ['Ratings', 'SD'], loc='upper right')\n",
    "\n",
    "ticks = [f'Batch {i}' for i in range(1, len(means_pp) + 1)]\n",
    "xs = np.arange(len(ticks))\n",
    "plt.xticks(xs+1, ticks)\n",
    "plt.grid(axis='y', linestyle=\"--\", alpha=0.5, zorder=1)\n",
    "\n",
    "\n",
    "plt.ylim(-0.2, 5.2)\n",
    "plt.xlim(0, 7)\n",
    "plt.title('Ratings per respondent')\n",
    "plt.savefig('respondents_ratings_box.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(stds_pp_1), np.mean(stds_pp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(means_pp_1), np.mean(means_pp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(all_averages['RELITC'], all_averages['Polyjuice'], c=all_averages['PPLM'], alpha=0.6)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(all_averages['RELITC'], all_averages['Polyjuice'], all_averages['PPLM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "031ecd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_fomc = survey_data[['Question_ID', 'Fact_ID']].drop_duplicates()\n",
    "\n",
    "indexes = all_rows.keys()\n",
    "fomc_indexes = [int(id_to_fomc[id_to_fomc['Question_ID'] == int(ix)]['Fact_ID'].iloc[0]) for ix in indexes]\n",
    "\n",
    "polyjuice = [np.mean(all_rows[ix]['Polyjuice']) for ix in indexes]\n",
    "pplm = [np.mean(all_rows[ix]['PPLM']) for ix in indexes]\n",
    "relitc = [np.mean(all_rows[ix]['RELITC']) for ix in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe65f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'q_id': indexes,\n",
    "    'id': fomc_indexes,\n",
    "    'polyjuice': polyjuice,\n",
    "    'pplm': pplm,\n",
    "    'relitc': relitc,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "672ec5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('non-expert_mean_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for means in means_pp: # intra-rater - means of means of person's ratings\n",
    "    print(np.mean(means), np.std(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ratings in all_all_ratings: # inter-rater (means of means of all the ratings in batch)\n",
    "    agg = []\n",
    "    for name in ratings:\n",
    "        agg += ratings[name]\n",
    "    print(np.mean(agg), np.std(agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_all_ratings[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f77a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388bc35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mice",
   "language": "python",
   "name": "mice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
