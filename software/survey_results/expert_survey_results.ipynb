{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5cd2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e8abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data = pd.read_csv('../survey/survey_data.csv')\n",
    "\n",
    "n = 5\n",
    "metrics = [1, 2]\n",
    "\n",
    "survey_responses = pd.read_csv('FINAL_EXP3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67117097",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64bf392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = survey_data.iloc[0][['Method_1', 'Method_2', 'Method_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "411ebd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_results(df):\n",
    "    questions = [x for x in df.columns if '_open_' in x]\n",
    "    qids = set([x.split('_')[2] for x in questions])\n",
    "    \n",
    "    n_ratings = 0\n",
    "    \n",
    "    all_ratings = {}\n",
    "    for question in questions:\n",
    "        split = question.split('_')\n",
    "        qid = split[2]\n",
    "        method = split[3]\n",
    "        \n",
    "        if int(qid) >= 5:\n",
    "            continue\n",
    "\n",
    "        ratings = df[question].dropna().iloc[2:].to_list()\n",
    "                \n",
    "        if len(ratings):\n",
    "            n_ratings += 1\n",
    "            if qid not in all_ratings:\n",
    "                all_ratings[qid] = {name: [] for name in method_names}\n",
    "            all_ratings[qid][method].append(ratings[0])\n",
    "                \n",
    "    \n",
    "    print(n_ratings)\n",
    "    \n",
    "    return all_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b270eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = get_text_results(survey_responses)\n",
    "          \n",
    "with open('expert_comments.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(comments, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43c2e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(df, success_only=True):\n",
    "    questions = [x for x in df.columns if '_mc_' in x]\n",
    "    qids = set([x.split('_')[2] for x in questions])\n",
    "\n",
    "    rows = {qid: {k: {m: [] for m in metrics} for k in method_names} for qid in qids}\n",
    "    for question in questions:\n",
    "        split = question.split('_')\n",
    "        qid = split[2]\n",
    "        method = split[3]\n",
    "        metric = int(split[4])\n",
    "        \n",
    "        if int(qid) >= 5:\n",
    "            continue\n",
    "        \n",
    "        if success_only:\n",
    "            if not survey_data[survey_data['Question_ID'] == int(qid)].iloc[0][f'{method}_Success']:\n",
    "                continue\n",
    "        \n",
    "        curr_metric = rows[qid][method][metric]\n",
    "\n",
    "        ratings = df[question].dropna().iloc[2:].to_list()\n",
    "        \n",
    "        \n",
    "        \n",
    "        for rating in ratings:\n",
    "            curr_metric.append(int(rating))\n",
    "            \n",
    "        curr_metric = curr_metric[:5]\n",
    "            \n",
    "    all_ratings = {k: {m: [] for m in metrics} for k in method_names}\n",
    "\n",
    "    for row in rows:\n",
    "        for method in rows[row]:\n",
    "            for metric in metrics:\n",
    "                if len(rows[row][method][metric]) > 0:\n",
    "                    all_ratings[method][metric].append(np.mean(rows[row][method][metric]))\n",
    "    \n",
    "    return all_ratings, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27aaf215",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings, rows = get_results(survey_responses, False)\n",
    "\n",
    "averaged = {name: {metric: [] for metric in metrics} for name in method_names}\n",
    "means = {str(i): {name: {metric: {} for metric in metrics} for name in method_names} for i in range(n)}\n",
    "for i in range(n):\n",
    "    i = str(i)\n",
    "    for method in method_names:\n",
    "        for metric in metrics:\n",
    "            if len(rows[i][method][metric]) == 0:\n",
    "                continue\n",
    "            means[i][method][metric] = {}\n",
    "            curr_means = means[i][method][metric]\n",
    "\n",
    "            curr_means['mean'] = np.mean(rows[i][method][metric])\n",
    "            curr_means['std'] = np.std(rows[i][method][metric])\n",
    "\n",
    "            averaged[method][metric].append(means[i][method][metric]['mean'])\n",
    "        \n",
    "\n",
    "for method in method_names:\n",
    "    for metric in metrics:\n",
    "        if len(averaged[method][metric]) == 0:\n",
    "            continue\n",
    "        average = np.mean(averaged[method][metric])\n",
    "        std = np.std(averaged[method][metric])\n",
    "\n",
    "        averaged[method][metric] = {'average': average, 'std': std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d5daf3",
   "metadata": {},
   "source": [
    "**ALL**\n",
    "\n",
    "| Generator |   Fluency       |   Plausibility  |\n",
    "|-----------|-----------------|-----------------|\n",
    "| PPLM | 2.27 (0.49)     | 1.83 (0.26)     |\n",
    "| Polyjuice      | 3.45 (0.91)     | **2.45** (0.66) |\n",
    "| RELITC    | **3.90** (0.60) | 2.12 (0.26)     |\n",
    "\n",
    "**SUCCESSFUL CE ONLY**\n",
    "\n",
    "| Generator |   Fluency       |   Plausibility  |\n",
    "|-----------|-----------------|-----------------|\n",
    "| PPLM | 3.0 (0.0)     | 1.75 (0.0)     |\n",
    "| Polyjuice      | 2.0 (0.0)     | **2.33** (0.0) |\n",
    "| RELITC    | **3.62** (0.27) | 2.10 (0.27)     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff090a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = [np.array([np.mean(ratings[x]) for x in ratings]) for ratings in all_all_ratings]\n",
    "all_stds = [np.array([np.std(ratings[x]) for x in ratings]) for ratings in all_all_ratings]\n",
    "\n",
    "# means_1 = np.array([np.mean(all_ratings[x]) for x in all_ratings])\n",
    "# stds_1 = np.array([np.std(all_ratings[x]) for x in all_ratings])\n",
    "\n",
    "# means_2 = np.array([np.mean(all_ratings_2[x]) for x in all_ratings_2])\n",
    "# stds_2 = np.array([np.std(all_ratings_2[x]) for x in all_ratings_2])\n",
    "\n",
    "# means_3 = np.array([np.mean(all_ratings_3[x]) for x in all_ratings_3])\n",
    "# stds_3 = np.array([np.std(all_ratings_3[x]) for x in all_ratings_3])\n",
    "\n",
    "# means_4 = np.array([np.mean(all_ratings_4[x]) for x in all_ratings_4])\n",
    "# stds_4 = np.array([np.std(all_ratings_4[x]) for x in all_ratings_4])\n",
    "\n",
    "means = np.mean(all_means, axis=0)\n",
    "stds = np.mean(all_stds, axis=0)\n",
    "\n",
    "xs = np.arange(len(method_names))\n",
    "\n",
    "plt.grid(axis='y', linestyle=\"--\", alpha=0.5, zorder=1)\n",
    "\n",
    "offset = 1 / (len(all_means) + 2)\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(all_means, all_stds)):\n",
    "    plt.bar(xs+(offset*i), mean, yerr=(std), width=offset, label=f'Batch {i+1}', capsize=5)\n",
    "\n",
    "# plt.bar(xs, means_1, yerr=(stds_1), width=offset, label='1st Batch', capsize=5)\n",
    "# plt.bar(xs+offset, means_2, yerr=(stds_2), width=offset, label='2nd Batch', capsize=5)\n",
    "# plt.bar(xs+2*offset, means_3, yerr=(stds_3), width=offset, label='3rd Batch', capsize=5)\n",
    "# plt.bar(xs+3*offset, means_4, yerr=(stds_4), width=offset, label='4th Batch', capsize=5)\n",
    "plt.bar(xs+offset*(len(means)+3), means, yerr=(stds), width=offset, label='Mean', capsize=5)\n",
    "\n",
    "plt.xticks(xs + offset * (len(means) / 2 + 1), method_names)\n",
    "plt.title('Four batches of ratings')\n",
    "plt.legend()\n",
    "plt.savefig('fourth_batch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_means, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da143354",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in all_ratings:\n",
    "    print(method, np.mean(all_ratings[method]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "936d3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses = [survey_responses, survey_responses_2, survey_responses_3, survey_responses_4, survey_responses_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38fa33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions = [[x for x in responses.columns if '_mc_' in x] for responses in all_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b3d96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_1 = [x for x in survey_responses.columns if '_mc_' in x]\n",
    "questions_2 = [x for x in survey_responses_2.columns if '_mc_' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3e53647",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings_per_person = [[row.dropna().astype(int).to_list() for i, row in responses.iloc[2:][questions].iterrows() if len(row.dropna()) > 0] for responses, questions in zip(all_responses, all_questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d33047f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_person_1 = [row.dropna().astype(int).to_list() for i, row in survey_responses.iloc[2:][questions_1].iterrows() if len(row.dropna()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "494edc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_person_2 = [row.dropna().astype(int).to_list() for i, row in survey_responses_2.iloc[2:][questions_2].iterrows() if len(row.dropna()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4728d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_pp = [[np.mean(x) for x in ratings_per_person] for ratings_per_person in all_ratings_per_person]\n",
    "stds_pp = [[np.std(x) for x in ratings_per_person] for ratings_per_person in all_ratings_per_person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86aba519",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_pp_1 = [np.mean(x) for x in ratings_per_person_1]\n",
    "means_pp_2 = [np.mean(x) for x in ratings_per_person_2]\n",
    "stds_pp_1 = [np.std(x) for x in ratings_per_person_1]\n",
    "stds_pp_2 = [np.std(x) for x in ratings_per_person_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid(axis='y', linestyle=\"--\", alpha=0.5, zorder=1)\n",
    "\n",
    "for i in range(len(means_pp)):\n",
    "    num_responses = len(means_pp[i])\n",
    "    plt.scatter([i+1]*num_responses, means_pp[i])\n",
    "    plt.scatter([i+1]*num_responses, stds_pp[i], color='black', label='Std')\n",
    "\n",
    "# plt.scatter([1]*5, means_pp_1)\n",
    "# plt.scatter([2]*5, means_pp_2)\n",
    "# plt.scatter([1]*5, stds_pp_1, label='Std', color='black')\n",
    "# plt.scatter([2]*5, stds_pp_2, color='black')\n",
    "\n",
    "ticks = [f'Batch {i}' for i in range(1, len(means_pp) + 1)]\n",
    "xs = np.arange(len(ticks))\n",
    "plt.xticks(xs+1, ticks)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(-0.2, 5.2)\n",
    "plt.xlim(0, 6)\n",
    "plt.title('Ratings per respondent (mean, std)')\n",
    "plt.savefig('respondents_ratings.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(stds_pp_1), np.mean(stds_pp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(means_pp_1), np.mean(means_pp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_fomc = survey_data[['Question_ID', 'Fact_ID']].drop_duplicates()\n",
    "\n",
    "indexes = rows.keys()\n",
    "fomc_indexes = [int(id_to_fomc[id_to_fomc['Question_ID'] == int(ix)]['Fact_ID'].iloc[0]) for ix in indexes]\n",
    "\n",
    "polyjuice_fluency = [np.mean(rows[ix]['Polyjuice'][1]) for ix in indexes]\n",
    "pplm_fluency = [np.mean(rows[ix]['PPLM'][1]) for ix in indexes]\n",
    "relitc_fluency = [np.mean(rows[ix]['RELITC'][1]) for ix in indexes]\n",
    "\n",
    "polyjuice_plausibility = [np.mean(rows[ix]['Polyjuice'][2]) for ix in indexes]\n",
    "pplm_plausibility = [np.mean(rows[ix]['PPLM'][2]) for ix in indexes]\n",
    "relitc_plausibility = [np.mean(rows[ix]['RELITC'][2]) for ix in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a37050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'q_id': indexes,\n",
    "    'id': fomc_indexes,\n",
    "    'polyjuice_fluency': polyjuice_fluency,\n",
    "    'pplm_fluency': pplm_fluency,\n",
    "    'relitc_fluency': relitc_fluency,\n",
    "    'polyjuice_plausibility': polyjuice_plausibility,\n",
    "    'pplm_plausibility': pplm_plausibility,\n",
    "    'relitc_plausibility': relitc_plausibility,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5ef095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('expert_mean_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1473f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mice",
   "language": "python",
   "name": "mice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
